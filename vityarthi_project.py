# -*- coding: utf-8 -*-
"""VITYARTHI PROJECT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jsQjLE4-UsYP3OHUksmMoLTxt0Ciq2X1
"""

!pip install -qU pandas scikit-learn nltk joblib emoji gradio transformers datasets torch accelerate sentencepiece
import nltk
nltk.download("stopwords")

import pandas as pd

sample = pd.DataFrame({
    "text": [
        "I love this product! ðŸ˜ Highly recommend.",
        "This is the worst. Totally disappointed.",
        "Not bad, could be better.",
        "Amazing experience, will buy again!",
        "Horrible service. Never again. ðŸ˜¡",
        "It's okay, nothing special.",
        "Decent product, but I've seen better.",
        "Absolutely fantastic, exceeded expectations!",
        "Don't waste your money, terrible quality.",
        "It's average, nothing to write home about.",
        "So happy with this purchase, five stars!",
        "Awful. Regret buying it.",
        "Could use some improvements, but functional.",
        "Fantastic product, a real game-changer.",
        "Seriously disappointed with the performance.",
        "Mediocre at best, would not recommend.",
        "This is great, I'm very satisfied.",
        "What a ripoff, completely useless.",
        "Neither good nor bad, just exists.",
        "Best thing I've bought all year!"
    ],
    "label": [
        "positive", "negative", "neutral", "positive", "negative", "neutral", "neutral",
        "positive", "negative", "neutral", "positive", "negative", "neutral",
        "positive", "negative", "neutral", "positive", "negative", "neutral", "positive"
    ]
})
sample.to_csv("sample_tweets.csv", index=False)
print("Saved sample_tweets.csv. To use your own data, upload a CSV and set DATA_PATH accordingly.")

import re
import emoji
from nltk.corpus import stopwords

STOP = set(stopwords.words("english"))

def clean_text(text, demojize=True):
    """Lightweight tweet cleaning. Keeps emoji as text tokens (demojized)."""
    text = str(text)
    if demojize:
        text = emoji.demojize(text, delimiters=(" ", " "))
    text = text.lower()
    text = re.sub(r"http\S+", " ", text)
    text = re.sub(r"@\w+", " ", text)
    text = re.sub(r"#", " ", text)
    text = re.sub(r"[^a-z0-9\s_:\-]", " ", text)
    text = re.sub(r"\s+", " ", text).strip()
    tokens = [t for t in text.split() if (t not in STOP and len(t) > 0)]
    return " ".join(tokens)


print(clean_text("I love this! ðŸ˜ http://x.com #awesome @user"))

DATA_PATH = "sample_tweets.csv"

import os, json, joblib
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix

df = pd.read_csv(DATA_PATH).dropna(subset=["text","label"]).reset_index(drop=True)
print("Loaded", len(df), "rows.")


label_values = sorted(df["label"].unique())
label_map = {lab: idx for idx, lab in enumerate(label_values)}
df["label_id"] = df["label"].map(label_map)


df["clean"] = df["text"].astype(str).apply(clean_text)


X = df["clean"]
y = df["label_id"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, stratify=y, random_state=42)


tfidf = TfidfVectorizer(ngram_range=(1,2), max_features=20000)
Xtr = tfidf.fit_transform(X_train)
Xte = tfidf.transform(X_test)

clf = LogisticRegression(max_iter=400)
clf.fit(Xtr, y_train)

y_pred = clf.predict(Xte)
print("=== Classification report ===")
print(classification_report(y_test, y_pred, target_names=label_values))
print("=== Confusion matrix ===")
print(confusion_matrix(y_test, y_pred))


os.makedirs("models", exist_ok=True)
joblib.dump(tfidf, "models/tfidf.joblib")
joblib.dump(clf, "models/logreg.joblib")
with open("models/label_map.json", "w") as f:
    json.dump(label_map, f)

print("Baseline TF-IDF + LR model saved to models/")

import joblib, json
tfidf = joblib.load("models/tfidf.joblib")
clf = joblib.load("models/logreg.joblib")
with open("models/label_map.json","r") as f:
    label_map = json.load(f)
inv_label_map = {v: k for k, v in label_map.items()}

def predict_baseline(text):
    vec = tfidf.transform([clean_text(text)])
    pred = int(clf.predict(vec)[0])
    probs = clf.predict_proba(vec)[0]
    return inv_label_map[pred], {inv_label_map[i]: float(probs[i]) for i in range(len(probs))}

print(predict_baseline("I hate this product! Worst ever ðŸ˜¡"))
print(predict_baseline("Absolutely fantastic â€” loved it! â¤ï¸"))

from datasets import Dataset
from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score
import torch

DATA_PATH = "sample_tweets.csv"
df = pd.read_csv(DATA_PATH).dropna(subset=["text","label"]).reset_index(drop=True)
label_values = sorted(df["label"].unique())
label_map = {lab: idx for idx, lab in enumerate(label_values)}
df["label_id"] = df["label"].map(label_map)

train_df, val_df = train_test_split(df, test_size=0.15, stratify=df["label_id"], random_state=42)
train_ds = Dataset.from_pandas(train_df[["text","label_id"]].rename(columns={"label_id":"label"}))
val_ds = Dataset.from_pandas(val_df[["text","label_id"]].rename(columns={"label_id":"label"}))

model_name = "distilbert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_name)

def preprocess_fn(batch):
    texts = [clean_text(t) for t in batch["text"]]
    return tokenizer(texts, padding="max_length", truncation=True, max_length=128)

train_ds = train_ds.map(preprocess_fn, batched=True)
val_ds = val_ds.map(preprocess_fn, batched=True)
train_ds.set_format(type="torch", columns=["input_ids","attention_mask","label"])
val_ds.set_format(type="torch", columns=["input_ids","attention_mask","label"])

model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(label_map))

def compute_metrics(eval_pred):
    logits, labels = eval_pred
    preds = np.argmax(logits, axis=-1)
    f1 = f1_score(labels, preds, average="macro")
    return {"f1_macro": float(f1)}

training_args = TrainingArguments(
    output_dir="distilbert_sentiment",
    eval_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=32,
    num_train_epochs=3,
    weight_decay=0.01,
    load_best_model_at_end=True,
    metric_for_best_model="f1_macro",
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_ds,
    eval_dataset=val_ds,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics
)

print("Transformer setup finished. To actually train, run:")
print(">>> trainer.train()  # (requires GPU)")
print("After training, save the model with trainer.save_model('models/distilbert_sentiment') and tokenizer.save_pretrained('models/distilbert_sentiment').")

import gradio as gr
import joblib, json, os
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch


tfidf = joblib.load("models/tfidf.joblib") if os.path.exists("models/tfidf.joblib") else None
clf = joblib.load("models/logreg.joblib") if os.path.exists("models/logreg.joblib") else None
label_map = json.load(open("models/label_map.json")) if os.path.exists("models/label_map.json") else None
inv_label_map = {v:k for k,v in label_map.items()} if label_map is not None else None


transformer_model_dir = "models/distilbert_sentiment"
if os.path.exists(transformer_model_dir):
    tokenizer_tf = AutoTokenizer.from_pretrained(transformer_model_dir)
    transformer = AutoModelForSequenceClassification.from_pretrained(transformer_model_dir)
    transformer.eval()
else:
    tokenizer_tf = transformer = None

def predict_fn(text, model_choice="Baseline"):
    t = clean_text(text)
    if model_choice == "Transformer" and transformer is not None:
        inputs = tokenizer_tf(t, return_tensors="pt", truncation=True, padding=True, max_length=128)
        with torch.no_grad():
            logits = transformer(**inputs).logits
            probs = torch.softmax(logits, dim=1).cpu().numpy()[0]
            lab = int(probs.argmax())
            label = inv_label_map[lab] if inv_label_map is not None else str(lab)
            return label, {inv_label_map[i]: float(probs[i]) for i in range(len(probs))}
    elif model_choice == "Baseline" and tfidf is not None and clf is not None:
        vec = tfidf.transform([t])
        probs = clf.predict_proba(vec)[0]
        lab = int(probs.argmax())
        label = inv_label_map[lab] if inv_label_map is not None else str(lab)
        return label, {inv_label_map[i]: float(probs[i]) for i in range(len(probs))}
    else:
        return "No model found. Train baseline or save DistilBERT to models/distilbert_sentiment.", {}

iface = gr.Interface(
    fn=predict_fn,
    inputs=[gr.Textbox(lines=4, placeholder="Paste tweet here..."), gr.Radio(["Baseline","Transformer"], value="Baseline")],
    outputs=[gr.Label(num_top_classes=3), gr.JSON()],
    title="Tweet Sentiment Demo",
    description="Baseline = TF-IDF + LogisticRegression. Transformer = DistilBERT if you trained & saved it."
)

iface.launch(share=False)